원래 텐서플로우 기준으로 설명하면
batch, 31, 11, 256일때
이걸 batch, 31*11, 256으로 만들고
gap는 tf.math.mean(data,axis=1)하거든요?
이게 결국에는 batch, 256의 데이터를 만드는 과정이고
그 다음에 그걸 linear 연산으로 보내는게 원래 tensorflow 코드임
그거는 그 안심용 채널에도 올라가있지만
CAM이라는 방법에서 쓰는 방법이고
지금은 그냥CNN을 하고 나서 어떻게 MLP로 전달하는지에 대한건데
그렇게 일반적인 CNN의 적용방식에서는
지금 CNN을 지나서 나온 데이터가 batch, 256, 31,11과 같이 차원이 많아서
바로 linear 연산에 들어갈 수 가 없어요
linear 연산은 (batch, X)사이즈의 인풋텐서만 처리할 수 있기 떄문에
그래서 flatten을 하면 batch, 256*31*11 의 방식으로
그렇게 flatten해서 linear 연산하는거에요
ㅇㅋ?